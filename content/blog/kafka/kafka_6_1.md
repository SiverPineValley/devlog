---
title: '6-1) 컨슈머'
date: 2024-01-11 16:00:00
category: 'kafka'
draft: false
---

## 6-1-1) 카프카 컨슈머 소개

- 카프카 프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머에 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다.

</br>

## 6-1-2) 컨슈머 내부 구조 (Java 라이브러리)

<div align="left">
  <img src="./images/스크린샷 2025-01-11 오후 2.50.08.png" width="500px" />
</div>

- **Fetcher**: 리더 파티션으로 부터 데이터를 미리 가져와서 대기
- **poll()**: Fetcher에 있는 레코드들을 리턴하는 레코드.
- **ConsumerRecords**: 처리하고자 하는 레코드들의 모임. 오프셋이 포함되어 있다.
- **Commit**: 특정 레코드를 처리하였는지에 대한 여부.

</br>

## 6-1-3) 컨슈머 그룹

- 컨슈머 그룹은 각기 다른 로직을 가진 애플리케이션(컨슈머)들이 같은 데이터를 처리하고자 할 때 사용하는 운영 방식이다.
- 컨슈머 그룹은 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식이다. 컨슈머 그룹으로 묶인 컨슈머들은 1개 이상의 파티션들에 할당되어 데이터를 가져갈 수 있다. 컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때 1개의 파티션은 최대 1개의 컨슈머에 할당 가능하다. 그리고 1개의 컨슈머는 여러 파티션에 할당될 수 있다. 이러한 특징으로 컨슈머 그룹의 컨슈머 개수는 가져가고자하는 토픽의 파티션 개수보다 같거나 작아야 한다.
- 컨슈머의 개수가 파티션 수보다 많은 경우에는 파티션에 매핑되지 못한 컨슈머들은 유휴상태로 남아 어떠한 컨슈머 로직도 처리하지 않는 불필요한 쓰레드가 된다.

</br>

### 6-1-3-1) 컨슈머 그룹을 활용하는 이유

- 운영 서버의 주요 리소스 (CPU, Memory, Disk)를 모니터링하는 데이터 파이프라인을 구축한다고 하자. 실시간 리소스를 시간순으로 확인하기 위해 데이터를 엘라스틱서치에 저장하고 이와 동시에 대용량 적재를 위해 하둡에 적재할 것이다. 만약 카프카를 사용한 파이프라인이 아닐 경우 서버에서 수행되는 리소스 수집 및 전송 에이전트는 동기 방식으로 요청할 것이다. 이렇게 동기 방식으로 데이터를 적재하는 경우 장애 발생 시 적재가 불가능할 수 있다.
- 컨슈머 개수가 파티션 개수보다 많은 경우 최종 적재되는 저장소의 장애에 유연하게 대처하기 위해 다른 저장소에 저장하는 컨슈머를 각기 다른 컨슈머 그룹으로 묶어서 운영할 수 있다. 이러한 방식을 통해 각 데이터 파이프라인을 디커플링하여 운영할 수 있다.

</br>

## 6-1-4) 리밸런싱

- 카프카 컨슈머 그룹의 일부 컨슈머에 장애가 발생하면 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어간다. 이러한 과정을 리밸런싱(Rebalancing)이라고 한다. 리밸런싱은 크게 두 가지 상황에서 발생한다.
1) **컨슈머가 추가되는 상황**
2) **컨슈머가 제외되는 상황**
- 이러한 리밸런싱은 컨슈머가 데이터를 처리하는 동안 언제든 발생할 수 있으므로, 이에 대응하기 위한 코드를 작성해놓아야 한다. 이를 처리하는 함수를 RebalanceListener라고 한다.

</br>

## 6-1-5) 커밋

- 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋(commit)을 통해 기록한다. 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 까지 가져갔는지 카프카 브로커 내부에서 사용되는 내부 토픽 (consumer_offset)에 기록된다. 커밋이 제대로 이루어지지 않으면 중복 처리되는 로직이 발생할 수 있으므로, 컨슈머 로직 처리 후 반드시 커밋이 되어야 한다.

</br>

## 6-1-6) Assigner

- 컨슈머와 파티션 할당 정책은 컨슈머의 Assigner에 의해 발생한다. 카프카에서는 `RangeAssigner`, `RoundRobinAssigner`, `StickyAssigner`를 제공하고 있다.
	`RangeAssigner`: 각 토픽에서 파티션을 숫자로 정렬. 컨슈머를 사전 순서로 정렬하여 할당.
	`RoundRobinAssigner`: 모든 파티션을 컨슈머에서 번갈아가며 할당.
	`StickyAssigner`: 최대한 파티션을 균등하게 분배하면서 할당

</br>

## 6-1-7) 컨슈머의 주요 옵션

- `bootstrap.servers`: 프로듀서가 데이터를 전송할 대상 카프카 클러스터가 속한 브로커의 호스트:포트를 1개 이상 작성한다. 
- `key.deserilaizer`: 레코드의 메시지 키를 역직렬화하는 클래스를 지정한다.
- `value.deserializer`: 레코드의 메시지 값을 역직렬화하는 클래스를 지정한다.

</br>

### 6-1-7-1) 컨슈머의 선택 옵션

- `group.id`: 컨슈머 그룹 ID를 지정한다. subscribe()로 토픽을 구독하여 사용할 때는 필수적으로 넣어줘야 한다. 기본 값은 null이다.
- `auto.offset.reset`: 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 파티션 오프셋이 없을 때 (커밋이 없는 경우) 어느 오프셋부터 읽을 지 선택하는 값이다. 이미 컨슈머 오프셋이 있다면, 이 옵션은 무시된다. 기본 값은 latest이다.
- `enable.auto.commit`: 자동 커밋으로 할지 수동 커밋으로 할지 지정한다. 기본 값은 true이다.
- `auto.commit.interval.ms`: 자동 커밋일 경우 커밋 간 간격을 지정한다. 기본 값은 5000ms(5초) 이다.
- `max.poll.records`: poll() 메서드를 통해 반환되는 레코드 수를 지정한다. 기본 값은 500이다.
- `session.timeout.ms`: 컨슈머와 브로커 연결이 끊기는 최대 시간이다. 기본 값은 10000ms(10초)이다.
- `heartbeat.interval.ms`: 하트비트를 전송하는 시간 간격이다. 기본 값은 3000ms(3초)이다.
- `max.poll.interval.ms`: poll() 메소드를 호출하는 간격의 최대 시간. 기본 값은 300000ms(5분)이다.
- `isolation.level`: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용된다.

</br>

## 6-1-8) auto.offset.reset

- 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머의 오프셋이 없을 때 어느 오프셋부터 읽을 지를 설정한다. 이미 컨슈머에 오프셋이 있다면 무시된다. 이 옵션은 latest, earliest, none 중 1개를 설정할 수 있다.
- `latest`: 설정하면 가장 높은 (가장 최근에 넣은) 오프셋부터 읽기 시작한다.
- `earliest`: 설정하면 가장 낮은 (가장 처음에 넣은) 오프셋부터 읽기 시작한다.
- `none`: 설정하면 컨슈머 그룹이 커밋한 기록이 있는지 찾아 본다. 커밋 기록이 없으면 오류를 반환하고, 커밋 기록이 있다면 기존 커밋 기록 오프셋부터 읽기 시작한다. 기본 값은 latest이다.